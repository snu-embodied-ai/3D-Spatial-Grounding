uni3d:
  pc_model: eva02_base_patch14_448
  pretrained_pc: ""
  ckpt_path: model/Uni3D/path/to/checkpoints/model.pt
  drop_path_rate: 0.20

  PointcloudEncoder:
    token_unit: region
    pc_feat_dim: 768
    embed_dim: 1024
    group_size: 64
    num_group: 512
    pc_encoder_dim: 512
    patch_dropout: 0.0

CLIP:
  model_name: EVA02-E-14-plus
  pretrained_path: model/Uni3D/path/to/clip_model/open_clip_pytorch_model.bin
  context_length: 77
  hidden_dim: 1024
  to_CPU: False

DINO:
  use_embed2trans_projector: True
  use_shared_embed2trans_projector: False
  vision_position_encoding: learnable       # learnable, sine, sequential
  text_position_encoding: learnable         # learnable, sine, sequential
  hidden_dim: 1024
  dim_feedforward: 1024
  num_heads: 8
  num_biformers: 3
  dropout: 0.1
  pre_norm: false
  # use_level_embed: false
  # normalize_pos_enc: true
  # positional_encoding_type: fourier
  # gauss_scale: 1.0
  # hlevels: [0,1,2,3]
  # clip_classifier: True
  temperature: 0.1

  use_attention_decoder: True

  Queries:
    num_queries: 128


OccupancyHead:
  heatmap_gen_method: "basic_unet"          # "self attention", "cross attention", "basic_unet"
  num_tokens: 350
  heatmap_shape: [400, 250]
  kernel_size: [5, 2, 1]
  strides: [5, 2, 1]
  conv_channels: [1024, 256, 16, 4]
  occ_conv_channels: [1024, 256, 16, 4]
  conv_n_heads: [8, 8, 1]
  dropout: 0.2

HeatmapHead:
  heatmap_gen_method: "basic_unet"          # "self attention", "cross attention", "basic_unet"
  num_tokens: 128
  heatmap_shape: [400, 250]
  kernel_size: [5, 2, 1]
  strides: [5, 2, 1]
  conv_channels: [1024, 128, 2, 1]
  occ_conv_channels: [1024, 128, 2, 1]
  conv_n_heads: [8, 8, 1]
  dropout: 0.2

use_whole_scene: False
distributed: False